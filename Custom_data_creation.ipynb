{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parishri07/Learning-PyTorch/blob/main/Custom_data_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "350701ec-c5f9-4809-884c-69a5dcf97ceb",
      "metadata": {
        "id": "350701ec-c5f9-4809-884c-69a5dcf97ceb"
      },
      "source": [
        "# PyTorch Custom Data Creation (from Food101)\n",
        "\n",
        "I'll get the images for 3 classes: Pizza, Steak, Sushi and store them in their respective files.\n",
        "\n",
        "\n",
        "Want:\n",
        "\n",
        "```\n",
        "pizza_steak_sushi/\n",
        "    train/\n",
        "        pizza/\n",
        "            image01.jpeg\n",
        "            image02.jpeg\n",
        "            ...\n",
        "        steak/\n",
        "            image04.jpeg\n",
        "            image05.jpeg\n",
        "            ...\n",
        "        sushi/\n",
        "            image07.jpeg\n",
        "            ...\n",
        "    test/\n",
        "        pizza/\n",
        "            image101.jpeg\n",
        "            image102.jpeg\n",
        "            ...\n",
        "        steak/\n",
        "            image104.jpeg\n",
        "            image105.jpeg\n",
        "            ...\n",
        "        sushi/\n",
        "            image107.jpeg\n",
        "            ...\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4ea443bb-470a-47e5-8f4d-341abf4e4d6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ea443bb-470a-47e5-8f4d-341abf4e4d6f",
        "outputId": "4d269545-a734-4f33-f3d4-fd254d5d281a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version is good!\n",
            "torchvision version is good!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n",
            "    lambda f: self._run_callback(functools.partial(callback, future))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n",
            "    ret = callback()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n",
            "    self.ctx_run(self.run)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n",
            "    yielded = self.gen.send(value)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n",
            "    yield gen.maybe_future(dispatch(*args))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
            "    yield gen.maybe_future(handler(stream, idents, msg))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n",
            "    self.do_execute(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n",
            "    yielded = ctx_run(next, result)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
            "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
            "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-758cb8ac1f74>\", line 2, in <cell line: 2>\n",
            "    import torchvision\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\", line 5, in <module>\n",
            "    from torchvision import datasets, io, models, ops, transforms, utils\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/__init__.py\", line 17, in <module>\n",
            "    from . import detection, optical_flow, quantization, segmentation, video\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/__init__.py\", line 1, in <module>\n",
            "    from .faster_rcnn import *\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/faster_rcnn.py\", line 16, in <module>\n",
            "    from .anchor_utils import AnchorGenerator\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/anchor_utils.py\", line 10, in <module>\n",
            "    class AnchorGenerator(nn.Module):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/anchor_utils.py\", line 63, in AnchorGenerator\n",
            "    device: torch.device = torch.device(\"cpu\"),\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/anchor_utils.py:63: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:77.)\n",
            "  device: torch.device = torch.device(\"cpu\"),\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Check PyTorch version and warn if it's too old\n",
        "if int(torch.__version__.split(\".\")[1]) < 11:\n",
        "    print(\"Warning: PyTorch version is less than 1.11.0. Food101 dataset might not work properly.\")\n",
        "else:\n",
        "    print(\"PyTorch version is good!\")\n",
        "\n",
        "if int(torchvision.__version__.split(\".\")[1]) < 12:\n",
        "    print(\"Warning: torchvision version is less than 0.12.0. Food101 dataset might not work properly.\")\n",
        "else:\n",
        "    print(\"torchvision version is good!\")\n",
        "\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Setup data directory\n",
        "import pathlib\n",
        "data_dir = pathlib.Path(\"../data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22f42bd9-459c-44cb-a0cf-d1b24599ff81",
      "metadata": {
        "id": "22f42bd9-459c-44cb-a0cf-d1b24599ff81"
      },
      "source": [
        "## Download data\n",
        "\n",
        "Get the Food101 dataset from PyTorch.\n",
        "* Food101 in `torchvision.datasets` - https://pytorch.org/vision/stable/generated/torchvision.datasets.Food101.html\n",
        "* Original Food101 dataset - https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/\n",
        "\n",
        "> **Note:** Downloading the dataset from PyTorch may take ~10-15 minutes depending on your internet speed. It will download ~5GB of data to the specified `root` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6304649-b3d2-4341-8adb-4d0382415d4d",
      "metadata": {
        "id": "f6304649-b3d2-4341-8adb-4d0382415d4d"
      },
      "outputs": [],
      "source": [
        "# Get training data\n",
        "train_data = datasets.Food101(root=data_dir,\n",
        "                              split=\"train\",\n",
        "                              # transform=transforms.ToTensor(),\n",
        "                              download=True)\n",
        "\n",
        "# Get testing data\n",
        "test_data = datasets.Food101(root=data_dir,\n",
        "                             split=\"test\",\n",
        "                             # transform=transforms.ToTensor(),\n",
        "                             download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12d418e1-9eb9-4cb4-abc0-03c6d8b1a637",
      "metadata": {
        "id": "12d418e1-9eb9-4cb4-abc0-03c6d8b1a637"
      },
      "outputs": [],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43e6ea58-9b35-4321-a27b-eb6bed2afc19",
      "metadata": {
        "id": "43e6ea58-9b35-4321-a27b-eb6bed2afc19"
      },
      "outputs": [],
      "source": [
        "class_names = train_data.classes\n",
        "class_names[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "315c8fea-b7b4-47e2-b71c-89d9d216de17",
      "metadata": {
        "id": "315c8fea-b7b4-47e2-b71c-89d9d216de17"
      },
      "outputs": [],
      "source": [
        "# View first sample (PIL Image format)\n",
        "print(class_names[train_data[0][1]])\n",
        "train_data[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d480e9b-9fd6-44fb-9bf6-512421db6900",
      "metadata": {
        "id": "3d480e9b-9fd6-44fb-9bf6-512421db6900"
      },
      "source": [
        "## Find subset of appropriate classes\n",
        "\n",
        "Want: Steak, pizza, sushi.\n",
        "\n",
        "Current path setup:\n",
        "\n",
        "```\n",
        "../data/food-101/images/CLASS_NAME/IMAGES.jpg\n",
        "```\n",
        "\n",
        "Going to get a list of the different target image classes (`pizza`, `steak`, `sushi`) filenames and then copy the images to separate folders.\n",
        "\n",
        "I'd like to get a random 10% of the images from the target classes from both datasets."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OqjCTjr1iYF",
        "outputId": "2cb09f48-8443-432d-fb38-ca362185224d"
      },
      "id": "8OqjCTjr1iYF",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1fb70f3d-54ce-4fcb-beb1-db57c31f61bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "1fb70f3d-54ce-4fcb-beb1-db57c31f61bb",
        "outputId": "e547cc6d-c939-4f77-9959-410150ff4649"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-4-4250f29bebd4>, line 23)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-4250f29bebd4>\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    label_path = /content/drive/MyDrive/Colab Notebooks/Satellite Image Classification dataset/{data_split}\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# Get random 10% of training images\n",
        "import random\n",
        "\n",
        "# Setup data paths\n",
        "data_path = '/content/drive/MyDrive/Colab Notebooks/Satellite Image Classification dataset'\n",
        "target_classes = [\"cloudy\", \"water\", \"green_area\"]\n",
        "\n",
        "# Change amount of data to get (e.g. 0.1 = random 10%, 0.2 = random 20%)\n",
        "amount_to_get = 0.2\n",
        "\n",
        "# Create function to separate a random amount of data\n",
        "def get_subset(image_path=data_path,\n",
        "               data_splits=[\"train\", \"test\"],\n",
        "               target_classes=[\"pizza\", \"steak\", \"sushi\"],\n",
        "               amount=0.1,\n",
        "               seed=42):\n",
        "    random.seed(42)\n",
        "    label_splits = {}\n",
        "\n",
        "    # Get labels\n",
        "    for data_split in data_splits:\n",
        "        print(f\"[INFO] Creating image split for: {data_split}...\")\n",
        "        label_path = /content/drive/MyDrive/Colab Notebooks/Satellite Image Classification dataset/{data_split}\n",
        "        with open(label_path, \"r\") as f:\n",
        "            labels = [line.strip(\"\\n\") for line in f.readlines() if line.split(\"/\")[0] in target_classes]\n",
        "\n",
        "        # Get random subset of target classes image ID's\n",
        "        number_to_sample = round(amount * len(labels))\n",
        "        print(f\"[INFO] Getting random subset of {number_to_sample} images for {data_split}...\")\n",
        "        sampled_images = random.sample(labels, k=number_to_sample)\n",
        "\n",
        "        # Apply full paths\n",
        "        image_paths = [pathlib.Path(str(image_path / sample_image) + \".jpg\") for sample_image in sampled_images]\n",
        "        label_splits[data_split] = image_paths\n",
        "    return label_splits\n",
        "\n",
        "label_splits = get_subset(amount=amount_to_get)\n",
        "label_splits[\"train\"][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe23d449-1f78-4798-b1af-9d1077e97922",
      "metadata": {
        "id": "fe23d449-1f78-4798-b1af-9d1077e97922"
      },
      "source": [
        "## Move training and testing images to dedicated folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f0f76b3-13dd-486e-8184-b205c69ffff3",
      "metadata": {
        "id": "4f0f76b3-13dd-486e-8184-b205c69ffff3"
      },
      "outputs": [],
      "source": [
        "# Create target directory path\n",
        "target_dir_name = f\"../data/pizza_steak_sushi_{str(int(amount_to_get*100))}_percent\"\n",
        "print(f\"Creating directory: '{target_dir_name}'\")\n",
        "\n",
        "# Setup the directories\n",
        "target_dir = pathlib.Path(target_dir_name)\n",
        "\n",
        "# Make the directories\n",
        "target_dir.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "143e39fd-b091-4fbd-88ef-4dc4af77fcd9",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "143e39fd-b091-4fbd-88ef-4dc4af77fcd9"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "for image_split in label_splits.keys():\n",
        "    for image_path in label_splits[str(image_split)]:\n",
        "        dest_dir = target_dir / image_split / image_path.parent.stem / image_path.name\n",
        "        if not dest_dir.parent.is_dir():\n",
        "            dest_dir.parent.mkdir(parents=True, exist_ok=True)\n",
        "        print(f\"[INFO] Copying {image_path} to {dest_dir}...\")\n",
        "        shutil.copy2(image_path, dest_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e59a2970-a67d-46e6-ac92-c6020587abe6",
      "metadata": {
        "id": "e59a2970-a67d-46e6-ac92-c6020587abe6"
      },
      "outputs": [],
      "source": [
        "# Check lengths of directories\n",
        "def walk_through_dir(dir_path):\n",
        "  \"\"\"\n",
        "  Walks through dir_path returning its contents.\n",
        "  Args:\n",
        "    dir_path (str): target directory\n",
        "\n",
        "  Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "  \"\"\"\n",
        "  import os\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "walk_through_dir(target_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53436482-2b03-473a-89a4-e51d3d57ab80",
      "metadata": {
        "id": "53436482-2b03-473a-89a4-e51d3d57ab80"
      },
      "source": [
        "Looks like we've got about ~75 training images per class and ~25 testing images per class (or more if you're using a higher percentage, e.g. ~150 training images per class and ~50 testing images per class for 20% of the data).\n",
        "\n",
        "This should be enough for a starting dataset.\n",
        "\n",
        "We can always increased them if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9063c379-5768-47d1-86bc-847d73f9517d",
      "metadata": {
        "id": "9063c379-5768-47d1-86bc-847d73f9517d"
      },
      "source": [
        "## Zip up images folder to be more easily transported"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aefdc45d-67fd-4eb2-8474-4e10249cfcd9",
      "metadata": {
        "id": "aefdc45d-67fd-4eb2-8474-4e10249cfcd9"
      },
      "outputs": [],
      "source": [
        "# Zip pizza_steak_sushi images\n",
        "zip_file_name = data_dir / f\"pizza_steak_sushi_{str(int(amount_to_get*100))}_percent\"\n",
        "shutil.make_archive(zip_file_name,\n",
        "                    format=\"zip\",\n",
        "                    root_dir=target_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d91f527d-9a57-4d00-a769-45239a06b0a7",
      "metadata": {
        "id": "d91f527d-9a57-4d00-a769-45239a06b0a7"
      },
      "outputs": [],
      "source": [
        "!ls -la ../data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a95e6d-891e-45fd-bf3b-2f105e5c18a8",
      "metadata": {
        "id": "f5a95e6d-891e-45fd-bf3b-2f105e5c18a8"
      },
      "outputs": [],
      "source": [
        "!mkdir -p pizza_steak_sushi\n",
        "!unzip ../data/pizza_steak_sushi_20_percent.zip -d pizza_steak_sushi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8deed237-f76d-465b-b252-062d72403fc8",
      "metadata": {
        "id": "8deed237-f76d-465b-b252-062d72403fc8"
      },
      "outputs": [],
      "source": [
        "!ls ../data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e9cbc5-a37a-4d70-8d65-4e181d69cace",
      "metadata": {
        "id": "03e9cbc5-a37a-4d70-8d65-4e181d69cace"
      },
      "outputs": [],
      "source": [
        "walk_through_dir(\"pizza_steak_sushi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1fa8ae0-e5cd-403e-a6ad-672b39f4f78f",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "c1fa8ae0-e5cd-403e-a6ad-672b39f4f78f"
      },
      "outputs": [],
      "source": [
        "# # Remove extra data\n",
        "# import os\n",
        "# os.remove(\"pizza_steak_sushi\")\n",
        "# shutil.rmtree(\"pizza_steak_sushi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff0e3511-cfae-4911-aff4-cc1044722226",
      "metadata": {
        "id": "ff0e3511-cfae-4911-aff4-cc1044722226"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fea4937-9354-4848-878f-d3dad0b2ac0c",
      "metadata": {
        "id": "1fea4937-9354-4848-878f-d3dad0b2ac0c"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}